{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPCtyFTtRZZ6gNizSIWIVej",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dpowale/LexiLogic/blob/main/LexiLogic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fOjbQzSvN5A4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "LexiLogic is a Streamlit web application that blends symbolic reasoning with large language models (LLMs) to analyze and interpret multilingual PDF documents ‚Äî especially in domains such as theology, law, history, and ideology where structured logic and contextual awareness are critical.\n",
        "\n",
        "Unlike purely statistical models, LexiLogic applies a symbolic AI chain-of-thought framework that mimics how a human expert might break down a complex document:\n",
        "\n",
        "üà∂ Detect the document's language (e.g., Arabic, English, etc.)\n",
        "\n",
        "üåê Translate non-English text to English (if needed)\n",
        "\n",
        "üß† Extract named entities and their relationships\n",
        "\n",
        "üßæ Identify the document‚Äôs main topics\n",
        "\n",
        "üìù Generate a contextual summary with ideological emphasis\n",
        "\n",
        "This app is especially useful for:\n",
        "\n",
        "Researchers studying religious, ideological, or political texts\n",
        "\n",
        "Analysts performing cross-language content audits\n",
        "\n",
        "Students and educators looking to summarize complex materials\n",
        "\n",
        "Intelligence teams doing content triage on foreign-language media\n",
        "\n",
        "LexiLogic is built using:\n",
        "\n",
        "üìÑ PyMuPDF for PDF text extraction\n",
        "\n",
        "üß† LangChain for prompt management\n",
        "\n",
        "üß¨ SymPy for symbolic logic (expandable)\n",
        "\n",
        "ü§ñ OpenAI LLM for reasoning\n",
        "\n",
        "üåê deep-translator for multilingual support\n",
        "\n",
        "It offers a unique, explainable alternative to black-box summarization ‚Äî enabling deeper insights and better alignment with human reasoning."
      ],
      "metadata": {
        "id": "Zta56fw2Mm6S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Required Libraries"
      ],
      "metadata": {
        "id": "oPlsGGEVJiTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit langchain_community openai sympy langdetect deep-translator PyMuPDF"
      ],
      "metadata": {
        "id": "DVkPJwaZI4cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt Chaining"
      ],
      "metadata": {
        "id": "3mfM6YW8H7nS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zk2ewblsCXVh"
      },
      "outputs": [],
      "source": [
        "# LexiLogic Streamlit App for Multilingual Document Analysis\n",
        "\n",
        "import os\n",
        "import streamlit as st\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langdetect import detect\n",
        "from deep_translator import GoogleTranslator\n",
        "from sympy import symbols, Eq, solve\n",
        "import fitz  # PyMuPDF\n",
        "\n",
        "# Configure LLM\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"  # Replace with your API key\n",
        "llm = OpenAI(temperature=0)\n",
        "\n",
        "# Prompt Templates\n",
        "ner_prompt = PromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    Extract named entities (e.g., people, ideologies, organizations, locations) and their relationships from the text:\n",
        "    {text}\n",
        "    \"\"\"\n",
        ")\n",
        "topic_prompt = PromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    Identify the main topics discussed in the following document:\n",
        "    {text}\n",
        "    \"\"\"\n",
        ")\n",
        "summary_prompt = PromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    Summarize the document with emphasis on its key arguments and ideological stance:\n",
        "    {text}\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "# LangChain chaining components like prompts, LLM, tools, and retrievers in a clean, composable way using \"|\"\n",
        "ner_chain = ner_prompt | llm\n",
        "topic_chain = topic_prompt | llm\n",
        "summary_chain = summary_prompt | llm\n",
        "\n",
        "# Core Functions\n",
        "def extract_text_from_pdf(file):\n",
        "    doc = fitz.open(stream=file.read(), filetype=\"pdf\")\n",
        "    full_text = \"\".join(page.get_text() for page in doc)\n",
        "    return full_text\n",
        "\n",
        "def detect_language(text):\n",
        "    return detect(text)\n",
        "\n",
        "def translate_to_english(text):\n",
        "    lang = detect_language(text)\n",
        "    if lang != 'en':\n",
        "        return GoogleTranslator(source='auto', target='en').translate(text)\n",
        "    return text\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PDF Documents Analysis"
      ],
      "metadata": {
        "id": "EE0O_3sdIYV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üìå Streamlit App UI\n",
        "st.set_page_config(page_title=\"LexiLogic Document Analyzer\", layout=\"wide\")\n",
        "st.title(\"üìö LexiLogic Multilingual Document Analyzer\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload a PDF document\", type=\"pdf\")\n",
        "\n",
        "if uploaded_file:\n",
        "    with st.spinner(\"üîç Processing PDF...\"):\n",
        "        raw_text = extract_text_from_pdf(uploaded_file)\n",
        "        translated_text = translate_to_english(raw_text)\n",
        "        language = detect_language(raw_text)\n",
        "\n",
        "        st.subheader(\"üà∂ Detected Language\")\n",
        "        st.write(language)\n",
        "\n",
        "        st.subheader(\"üîÅ Translated Text Sample\")\n",
        "        st.code(translated_text[:500])\n",
        "\n",
        "        st.subheader(\"üìå Named Entities & Relationships\")\n",
        "        ner_result = ner_chain.invoke({\"text\": translated_text})\n",
        "        st.write(ner_result)\n",
        "\n",
        "        st.subheader(\"üìö Topics\")\n",
        "        topics_result = topic_chain.invoke({\"text\": translated_text})\n",
        "        st.write(topics_result)\n",
        "\n",
        "        st.subheader(\"üìù Summary\")\n",
        "        summary_result = summary_chain.invoke({\"text\": translated_text})\n",
        "        st.write(summary_result)\n"
      ],
      "metadata": {
        "id": "2LpLHmKUNwd2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}